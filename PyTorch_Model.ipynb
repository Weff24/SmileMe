{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rI7aIb5sG48F",
        "outputId": "f6f1fccd-44d8-4fe8-ff17-2e9ad2dd851a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'SmileMe'...\n",
            "remote: Enumerating objects: 34176, done.\u001b[K\n",
            "remote: Counting objects: 100% (71/71), done.\u001b[K\n",
            "remote: Compressing objects: 100% (60/60), done.\u001b[K\n",
            "remote: Total 34176 (delta 31), reused 42 (delta 10), pack-reused 34105\u001b[K\n",
            "Receiving objects: 100% (34176/34176), 88.45 MiB | 18.65 MiB/s, done.\n",
            "Resolving deltas: 100% (43/43), done.\n",
            "Updating files: 100% (107692/107692), done.\n"
          ]
        }
      ],
      "source": [
        "!cd /content && git clone https://github.com/Weff24/SmileMe.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "jGGOIQxiHrp_",
        "outputId": "aca8dea6-46b9-443b-b6d8-709c4c5133a1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/SmileMe\n",
            "Using device:  cuda\n",
            "['angry', 'disgust', 'fear', 'happy', 'neutral', 'sad', 'surprise']\n",
            "['angry', 'disgust', 'fear', 'happy', 'neutral', 'sad', 'surprise']\n",
            "Target label:  neutral\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch:  1\n",
            "Iteration 0, loss = 2.4938\n",
            "Checking accuracy on validation set\n",
            "Got 907 / 7066 correct (12.84)\n",
            "\n",
            "Iteration 100, loss = 1.7960\n",
            "Checking accuracy on validation set\n",
            "Got 2331 / 7066 correct (32.99)\n",
            "\n",
            "Iteration 200, loss = 1.4644\n",
            "Checking accuracy on validation set\n",
            "Got 2636 / 7066 correct (37.31)\n",
            "\n",
            "Iteration 300, loss = 1.7121\n",
            "Checking accuracy on validation set\n",
            "Got 2987 / 7066 correct (42.27)\n",
            "\n",
            "Iteration 400, loss = 1.6300\n",
            "Checking accuracy on validation set\n",
            "Got 3308 / 7066 correct (46.82)\n",
            "\n",
            "epoch:  2\n",
            "Iteration 0, loss = 1.2174\n",
            "Checking accuracy on validation set\n",
            "Got 3421 / 7066 correct (48.41)\n",
            "\n",
            "Iteration 100, loss = 1.1797\n",
            "Checking accuracy on validation set\n",
            "Got 3206 / 7066 correct (45.37)\n",
            "\n",
            "Iteration 200, loss = 1.3264\n",
            "Checking accuracy on validation set\n",
            "Got 3339 / 7066 correct (47.25)\n",
            "\n",
            "Iteration 300, loss = 1.3537\n",
            "Checking accuracy on validation set\n",
            "Got 3680 / 7066 correct (52.08)\n",
            "\n",
            "Iteration 400, loss = 1.2696\n",
            "Checking accuracy on validation set\n",
            "Got 3134 / 7066 correct (44.35)\n",
            "\n",
            "epoch:  3\n",
            "Iteration 0, loss = 1.0876\n",
            "Checking accuracy on validation set\n",
            "Got 3260 / 7066 correct (46.14)\n",
            "\n",
            "Iteration 100, loss = 1.2521\n",
            "Checking accuracy on validation set\n",
            "Got 3914 / 7066 correct (55.39)\n",
            "\n",
            "Iteration 200, loss = 0.8987\n",
            "Checking accuracy on validation set\n",
            "Got 3617 / 7066 correct (51.19)\n",
            "\n",
            "Iteration 300, loss = 1.3303\n",
            "Checking accuracy on validation set\n",
            "Got 3950 / 7066 correct (55.90)\n",
            "\n",
            "Iteration 400, loss = 1.2057\n",
            "Checking accuracy on validation set\n",
            "Got 3788 / 7066 correct (53.61)\n",
            "\n",
            "epoch:  4\n",
            "Iteration 0, loss = 1.1475\n",
            "Checking accuracy on validation set\n",
            "Got 4030 / 7066 correct (57.03)\n",
            "\n",
            "Iteration 100, loss = 0.8694\n",
            "Checking accuracy on validation set\n",
            "Got 3881 / 7066 correct (54.92)\n",
            "\n",
            "Iteration 200, loss = 1.1303\n",
            "Checking accuracy on validation set\n",
            "Got 3660 / 7066 correct (51.80)\n",
            "\n",
            "Iteration 300, loss = 1.3220\n",
            "Checking accuracy on validation set\n",
            "Got 3938 / 7066 correct (55.73)\n",
            "\n",
            "Iteration 400, loss = 1.0708\n",
            "Checking accuracy on validation set\n",
            "Got 3716 / 7066 correct (52.59)\n",
            "\n",
            "epoch:  5\n",
            "Iteration 0, loss = 1.1047\n",
            "Checking accuracy on validation set\n",
            "Got 4045 / 7066 correct (57.25)\n",
            "\n",
            "Iteration 100, loss = 0.9495\n",
            "Checking accuracy on validation set\n",
            "Got 3984 / 7066 correct (56.38)\n",
            "\n",
            "Iteration 200, loss = 1.0064\n",
            "Checking accuracy on validation set\n",
            "Got 3971 / 7066 correct (56.20)\n",
            "\n",
            "Iteration 300, loss = 1.3255\n",
            "Checking accuracy on validation set\n",
            "Got 4052 / 7066 correct (57.35)\n",
            "\n",
            "Iteration 400, loss = 1.1651\n",
            "Checking accuracy on validation set\n",
            "Got 4043 / 7066 correct (57.22)\n",
            "\n",
            "epoch:  6\n",
            "Iteration 0, loss = 0.7211\n",
            "Checking accuracy on validation set\n",
            "Got 4018 / 7066 correct (56.86)\n",
            "\n",
            "Iteration 100, loss = 0.8159\n",
            "Checking accuracy on validation set\n",
            "Got 4076 / 7066 correct (57.68)\n",
            "\n",
            "Iteration 200, loss = 1.1559\n",
            "Checking accuracy on validation set\n",
            "Got 4123 / 7066 correct (58.35)\n",
            "\n",
            "Iteration 300, loss = 0.8913\n",
            "Checking accuracy on validation set\n",
            "Got 3930 / 7066 correct (55.62)\n",
            "\n",
            "Iteration 400, loss = 1.1872\n",
            "Checking accuracy on validation set\n",
            "Got 3915 / 7066 correct (55.41)\n",
            "\n",
            "epoch:  7\n",
            "Iteration 0, loss = 0.8647\n",
            "Checking accuracy on validation set\n",
            "Got 3815 / 7066 correct (53.99)\n",
            "\n",
            "Iteration 100, loss = 0.9304\n",
            "Checking accuracy on validation set\n",
            "Got 4121 / 7066 correct (58.32)\n",
            "\n",
            "Iteration 200, loss = 0.8774\n",
            "Checking accuracy on validation set\n",
            "Got 4160 / 7066 correct (58.87)\n",
            "\n",
            "Iteration 300, loss = 1.0278\n",
            "Checking accuracy on validation set\n",
            "Got 4134 / 7066 correct (58.51)\n",
            "\n",
            "Iteration 400, loss = 0.8035\n",
            "Checking accuracy on validation set\n",
            "Got 4115 / 7066 correct (58.24)\n",
            "\n",
            "epoch:  8\n",
            "Iteration 0, loss = 0.7680\n",
            "Checking accuracy on validation set\n",
            "Got 3993 / 7066 correct (56.51)\n",
            "\n",
            "Iteration 100, loss = 0.7876\n",
            "Checking accuracy on validation set\n",
            "Got 4066 / 7066 correct (57.54)\n",
            "\n",
            "Iteration 200, loss = 0.7132\n",
            "Checking accuracy on validation set\n",
            "Got 4241 / 7066 correct (60.02)\n",
            "\n",
            "Iteration 300, loss = 0.7178\n",
            "Checking accuracy on validation set\n",
            "Got 4135 / 7066 correct (58.52)\n",
            "\n",
            "Iteration 400, loss = 0.7532\n",
            "Checking accuracy on validation set\n",
            "Got 4293 / 7066 correct (60.76)\n",
            "\n",
            "epoch:  9\n",
            "Iteration 0, loss = 0.7241\n",
            "Checking accuracy on validation set\n",
            "Got 4014 / 7066 correct (56.81)\n",
            "\n",
            "Iteration 100, loss = 0.8220\n",
            "Checking accuracy on validation set\n",
            "Got 4258 / 7066 correct (60.26)\n",
            "\n",
            "Iteration 200, loss = 0.8515\n",
            "Checking accuracy on validation set\n",
            "Got 4127 / 7066 correct (58.41)\n",
            "\n",
            "Iteration 300, loss = 0.7537\n",
            "Checking accuracy on validation set\n",
            "Got 4198 / 7066 correct (59.41)\n",
            "\n",
            "Iteration 400, loss = 0.9331\n",
            "Checking accuracy on validation set\n",
            "Got 4227 / 7066 correct (59.82)\n",
            "\n",
            "epoch:  10\n",
            "Iteration 0, loss = 0.8381\n",
            "Checking accuracy on validation set\n",
            "Got 4329 / 7066 correct (61.27)\n",
            "\n",
            "Iteration 100, loss = 0.7225\n",
            "Checking accuracy on validation set\n",
            "Got 4209 / 7066 correct (59.57)\n",
            "\n",
            "Iteration 200, loss = 0.6890\n",
            "Checking accuracy on validation set\n",
            "Got 4270 / 7066 correct (60.43)\n",
            "\n",
            "Iteration 300, loss = 0.8403\n",
            "Checking accuracy on validation set\n",
            "Got 4330 / 7066 correct (61.28)\n",
            "\n",
            "Iteration 400, loss = 0.8576\n",
            "Checking accuracy on validation set\n",
            "Got 3964 / 7066 correct (56.10)\n",
            "\n",
            "Checking accuracy on validation set\n",
            "Got 4208 / 7066 correct (59.55)\n"
          ]
        }
      ],
      "source": [
        "%cd /content/SmileMe/\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn                   #for sequence api in torch\n",
        "from torch.utils.data import DataLoader #for loading images\n",
        "import numpy as np                      #just in case if you need numpy arrays\n",
        "import torchvision.transforms as transforms           #Used for data preprocessing and converting images to tensors\n",
        "import torchvision.datasets as datasets\n",
        "import torch.optim                      #For using the desired parameter update\n",
        "import torch.nn.functional\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "\n",
        "# check and set device\n",
        "if torch.cuda.is_available():\n",
        "  device = torch.device('cuda')\n",
        "else:\n",
        "  device = torch.device('cpu')\n",
        "\n",
        "print(\"Using device: \", device)\n",
        "\n",
        "num_pixels = 48\n",
        "\n",
        "# preprocessing\n",
        "transform = transforms.Compose([transforms.RandomHorizontalFlip(), transforms.Resize((num_pixels,num_pixels)), transforms.ToTensor()])\n",
        "train_data = datasets.ImageFolder(\"images/train\", transform=transform) # is it imagefolder? imagenet?\n",
        "loaded_train = DataLoader(train_data, batch_size=64, shuffle=True)\n",
        "validation_data = datasets.ImageFolder(\"images/validation\", transform=transform)\n",
        "loaded_validation = DataLoader(validation_data,batch_size=64, shuffle=True)\n",
        "print(train_data.classes)\n",
        "print(validation_data.classes)\n",
        "\n",
        "loss_history = []\n",
        "validation_acc = []\n",
        "training_acc = []\n",
        "\n",
        "# visualizing some sample data\n",
        "dataiter = iter(loaded_train)   #The iter() function in python represents the iterator similar to c++ iterators\n",
        "images, labels = next(dataiter) #The next() method retrieves the object \n",
        "expression = {0:\"angry\",1:\"disgust\",2:\"fear\",3:\"happy\",4:\"neutral\",5:\"sad\",6:\"surprise\"} #Create a dictionary for mapping accordingly\n",
        "random_idx = random.sample(range(0,64),1)[0]     #Selects a random single number from 0-64\n",
        "print(\"Target label: \",expression[int(labels[random_idx].numpy())])  #Converting it to numpy from tensor to fetch the label\n",
        "plt.imshow(np.transpose(images[random_idx].numpy(), (1, 2, 0)))\n",
        "plt.show()\n",
        "\n",
        "# function to check accuracy of model\n",
        "def check_accuracy_part(loader, model):\n",
        "    print('Checking accuracy on validation set')\n",
        "    num_correct = 0\n",
        "    num_samples = 0\n",
        "    model.eval()  # set model to evaluation mode\n",
        "    with torch.no_grad():\n",
        "        for x, y in loader:\n",
        "            x = x.to(device=device, dtype=torch.float32)  # move to device, e.g. GPU\n",
        "            y = y.to(device=device, dtype=torch.long)\n",
        "            scores = model(x)\n",
        "            _, preds = scores.max(1)\n",
        "            num_correct += (preds == y).sum()\n",
        "            num_samples += preds.size(0)\n",
        "        acc = float(num_correct) / num_samples\n",
        "        print('Got %d / %d correct (%.2f)' % (num_correct, num_samples, 100 * acc))\n",
        "\n",
        "# function to train the model\n",
        "def train_part(model, optimizer, epochs=1):\n",
        "    \"\"\"\n",
        "    Train a model using the PyTorch Module API.\n",
        "    \n",
        "    Inputs:\n",
        "    - model: A PyTorch Module giving the model to train.\n",
        "    - optimizer: An Optimizer object we will use to train the model\n",
        "    - epochs: (Optional) A Python integer giving the number of epochs to train for\n",
        "    \n",
        "    Returns: Nothing, but prints model accuracies during training.\n",
        "    \"\"\"\n",
        "    model = model.to(device=device)  # move the model parameters to CPU/GPU\n",
        "    for e in range(epochs):\n",
        "        print(\"epoch: \",e+1)\n",
        "        for t, (x, y) in enumerate(loaded_train):\n",
        "            model.train()  # put model to training mode\n",
        "            x = x.to(device=device, dtype=torch.float32)  # move to device, e.g. GPU\n",
        "            y = y.to(device=device, dtype=torch.long)\n",
        "\n",
        "            scores = model(x)\n",
        "            loss = torch.nn.functional.cross_entropy(scores, y)\n",
        "\n",
        "            # Zero out all of the gradients for the variables which the optimizer\n",
        "            # will update.\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # This is the backwards pass: compute the gradient of the loss with\n",
        "            # respect to each  parameter of the model.\n",
        "            loss.backward()\n",
        "\n",
        "            # Actually update the parameters of the model using the gradients\n",
        "            # computed by the backwards pass.\n",
        "            optimizer.step()\n",
        "\n",
        "            if t % 100 == 0:\n",
        "                print('Iteration %d, loss = %.4f' % (t, loss.item()))\n",
        "                check_accuracy_part(loaded_validation, model)\n",
        "                print()\n",
        "\n",
        "# Actually construct the model\n",
        "model = None\n",
        "optimizer = None\n",
        "\n",
        "#First architecture #3,32,32\n",
        "conv1 = nn.Sequential(\n",
        "    nn.Conv2d(3,512,kernel_size=(3,3),bias=True,padding=1), #512,48,48\n",
        "    nn.BatchNorm2d(512),\n",
        "    nn.ReLU(),\n",
        "    nn.MaxPool2d(kernel_size=(2,2))  #Sampling image to half  512,24,24\n",
        ")\n",
        "conv2 = nn.Sequential(\n",
        "    nn.Conv2d(512,128,kernel_size=(3,3),padding=1,bias=True), #128,24,24\n",
        "    nn.BatchNorm2d(128),\n",
        "    nn.ReLU(),\n",
        "    nn.MaxPool2d(kernel_size=(2,2))         #128,12,12\n",
        ")\n",
        "conv3 = nn.Sequential(\n",
        "    nn.Conv2d(128,64,kernel_size=(3,3),bias=True,padding=1), #64,12,12\n",
        "    nn.BatchNorm2d(64),\n",
        "    nn.ReLU(),\n",
        "    nn.MaxPool2d(kernel_size=(2,2))   #64,6,6\n",
        ")\n",
        "conv4 = nn.Sequential(\n",
        "    nn.Conv2d(64,256,kernel_size=(3,3),bias=True,padding=1), #64,6,6\n",
        "    nn.BatchNorm2d(256),\n",
        "    nn.ReLU(),\n",
        "    nn.MaxPool2d(kernel_size=(2,2))   #256,3,3\n",
        ")\n",
        "fc = nn.Sequential(\n",
        "    nn.Flatten(),\n",
        "    nn.Linear(256*3*3,7),\n",
        ")\n",
        "model = nn.Sequential(\n",
        "    conv1,\n",
        "    conv2,\n",
        "    conv3,\n",
        "    conv4,\n",
        "    fc\n",
        ")\n",
        "learning_rate=0.001\n",
        "optimizer = torch.optim.Adam(model.parameters(),lr=learning_rate)\n",
        "train_part(model, optimizer, epochs=10)\n",
        "\n",
        "# get the best model\n",
        "best_model = model\n",
        "check_accuracy_part(loaded_validation,best_model)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPN0moMhspqkIpAORBf4YtL"
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}